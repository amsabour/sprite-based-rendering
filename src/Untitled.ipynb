{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f8439f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb293edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dnnlib\n",
    "from dnnlib.util import EasyDict\n",
    "from utils import *\n",
    "import wandb\n",
    "import os\n",
    "import click\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "import math\n",
    "import time\n",
    "import gc\n",
    "import traceback\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "from networks.custom_modules import MultiShapeStyleLinearApproach\n",
    "from networks.stylegan import StyleGANDiscriminator\n",
    "\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd878bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f25269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True               # Improves training speed.\n",
    "torch.backends.cuda.matmul.allow_tf32 = False       # Improves numerical accuracy.\n",
    "torch.backends.cudnn.allow_tf32 = False             # Improves numerical accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff499625",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = dnnlib.EasyDict()\n",
    "c.steps = 6\n",
    "\n",
    "c.G_args = dnnlib.EasyDict()\n",
    "c.G_args.hidden_dim = 256\n",
    "c.G_args.hidden_action_dim = 512\n",
    "c.G_args.planner_type = 'mlp'\n",
    "c.G_args.num_actions = c.steps\n",
    "c.G_args.shape_style_dim = 256\n",
    "c.G_args.shape_encoding_dim = 64\n",
    "c.G_args.shape_progressive = True\n",
    "c.G_args.shape_num_sinusoidals = 6\n",
    "c.G_args.use_textures = False\n",
    "c.G_args.texture_progressive = True\n",
    "c.G_args.texture_num_sinusoidals = 4\n",
    "c.G_args.to_rgb_type = 'styled'\n",
    "c.G_args.output_size = 128\n",
    "c.feature_volume_size = 32\n",
    "c.G_args.const_in = False\n",
    "c.G_args.size_in = 8\n",
    "c.G_args.c_model = 32\n",
    "c.G_args.planner_lr_mul = 0.01\n",
    "c.G_args.shape_library_lr_mul = 1\n",
    "c.G_args.texture_library_lr_mul = 1\n",
    "\n",
    "\n",
    "c.device = torch.device('cuda')\n",
    "generator = MultiShapeStyleLinearApproach(**c.G_args).to(c.device)\n",
    "discriminator_dual = StyleGANDiscriminator(c.G_args.output_size, in_channels=6, channel_multiplier=1).to(c.device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2c46a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "noise = torch.randn(batch_size, c.G_args.hidden_dim).to(c.device)\n",
    "noise_generator = torch.zeros\n",
    "input_noise = [\n",
    "    noise_generator(batch_size, *_noise.shape[1:], device=c.device) for _noise in generator.to_rgb.get_noise_like()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d45a8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = c.G_args.output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac5089fc",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd003/home/amsabour/venv36/lib/python3.6/site-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "/ssd003/home/amsabour/hierarchical-decomposition-clean/src/networks/op/conv2d_gradfix_pre111.py:88: UserWarning: Using custom ops\n",
      "  warnings.warn(\"Using custom ops\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_forward : \t 0.430645227432251 +- 0.015960674464912235\n",
      "loss_calc     : \t 0.04855097830295563 +- 0.0008227695754198076\n",
      "model_backward: \t 0.8713723570108414 +- 0.004989595833739248\n"
     ]
    }
   ],
   "source": [
    "def trace_handler(p):\n",
    "    output = p.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=10)\n",
    "    print(output)\n",
    "    p.export_chrome_trace(\"trace_\" + str(p.step_num) + \".json\")\n",
    "\n",
    "\n",
    "forward_t = []\n",
    "loss_t = []\n",
    "backward_t = []\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "#     with_stack=True,\n",
    "#     with_flops=True,\n",
    "#     with_modules=True,\n",
    "#     schedule=torch.profiler.schedule(\n",
    "#         skip_first=4,\n",
    "#         wait=3,\n",
    "#         warmup=1,\n",
    "#         active=3,\n",
    "#         repeat=2),\n",
    "#     on_trace_ready=trace_handler\n",
    ") as prof:\n",
    "    for _ in range(16):\n",
    "        time_1 = time.time()\n",
    "        with record_function(\"model_forward\"):\n",
    "            input_noise = [\n",
    "                noise_generator(batch_size, *_noise.shape[1:], device=c.device) for _noise in generator.to_rgb.get_noise_like()\n",
    "            ]\n",
    "            generator_output = generator(noise, c.feature_volume_size, steps=c.steps, noise=input_noise, mode='sample')\n",
    "        torch.cuda.synchronize()\n",
    "        time_2 = time.time()\n",
    "        with record_function(\"loss_calculation\"):\n",
    "            samples = generator_output[f'renders/{c.steps}/render']\n",
    "            low_res_samples = generator_output[f'renders/{c.steps}/low_res_render']\n",
    "            masks = generator_output[f'renders/{c.steps}/segmentation']\n",
    "\n",
    "            # Dual discriminator loss\n",
    "            fake_pred_dual = discriminator_dual(torch.cat([samples, F.interpolate(low_res_samples, (size, size), mode='bilinear')], dim=1))\n",
    "            generator_dual_loss = F.softplus(-fake_pred_dual).mean()\n",
    "\n",
    "            # Mask consistency loss\n",
    "            mask_consistency_loss = torch.zeros([], device=c.device)\n",
    "            original_masks = rearrange(masks[0], 'b H W d -> b d H W')\n",
    "            for i in range(1, len(masks) - 1):\n",
    "                low_res_masks = rearrange(masks[i], 'b H W d -> b d H W')\n",
    "                high_res_masks = rearrange(masks[i + 1], 'b H W d -> b d H W')\n",
    "\n",
    "                if high_res_masks.shape[-1] > original_masks.shape[-1]:\n",
    "                    high_res_into_low_res_masks = F.interpolate(high_res_masks, (low_res_masks.shape[-2], low_res_masks.shape[-1]), mode='bilinear')\n",
    "                    mask_consistency_loss += F.mse_loss(low_res_masks, high_res_into_low_res_masks)\n",
    "\n",
    "            generator_loss = generator_dual_loss + mask_consistency_loss * 1.0\n",
    "        torch.cuda.synchronize()\n",
    "        time_3 = time.time()\n",
    "\n",
    "        with record_function(\"model_backward\"):\n",
    "            generator_loss.mean().backward()\n",
    "        torch.cuda.synchronize()\n",
    "        time_4 = time.time()\n",
    "        \n",
    "        forward_t.append(time_2 - time_1)\n",
    "        loss_t.append(time_3 - time_2)\n",
    "        backward_t.append(time_4 - time_3)\n",
    "        \n",
    "#         prof.step()\n",
    "    \n",
    "# prof.export_chrome_trace(\"trace.json\")\n",
    "# prof.export_stacks(\"profiler_stacks.txt\", \"self_cuda_time_total\")\n",
    "# print(prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cuda_time_total\", row_limit=5))\n",
    "\n",
    "print(f\"model_forward : \\t {np.mean(forward_t)} +- {np.std(forward_t)}\")\n",
    "print(f\"loss_calc     : \\t {np.mean(loss_t)} +- {np.std(loss_t)}\")\n",
    "print(f\"model_backward: \\t {np.mean(backward_t)} +- {np.std(backward_t)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b709db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2723596c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f1e1a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_forward : \t 0.42754605412483215 +- 0.01359851692440814\n",
      "loss_calc     : \t 0.049103811383247375 +- 0.0009719820773462114\n",
      "model_backward: \t 0.8699076175689697 +- 0.0037340833535047836\n"
     ]
    }
   ],
   "source": [
    "forward_t = []\n",
    "loss_t = []\n",
    "backward_t = []\n",
    "\n",
    "for _ in range(16):\n",
    "    time_1 = time.time()\n",
    "    with record_function(\"model_forward\"):\n",
    "        input_noise = [\n",
    "            noise_generator(batch_size, *_noise.shape[1:], device=c.device) for _noise in generator.to_rgb.get_noise_like()\n",
    "        ]\n",
    "        generator_output = generator(noise, c.feature_volume_size, steps=c.steps, noise=input_noise, mode='sample')\n",
    "    torch.cuda.synchronize()\n",
    "    time_2 = time.time()\n",
    "    with record_function(\"loss_calculation\"):\n",
    "        samples = generator_output[f'renders/{c.steps}/render']\n",
    "        low_res_samples = generator_output[f'renders/{c.steps}/low_res_render']\n",
    "        masks = generator_output[f'renders/{c.steps}/segmentation']\n",
    "\n",
    "        # Dual discriminator loss\n",
    "        fake_pred_dual = discriminator_dual(torch.cat([samples, F.interpolate(low_res_samples, (size, size), mode='bilinear')], dim=1))\n",
    "        generator_dual_loss = F.softplus(-fake_pred_dual).mean()\n",
    "\n",
    "        # Mask consistency loss\n",
    "        mask_consistency_loss = torch.zeros([], device=c.device)\n",
    "        original_masks = rearrange(masks[0], 'b H W d -> b d H W')\n",
    "        for i in range(1, len(masks) - 1):\n",
    "            low_res_masks = rearrange(masks[i], 'b H W d -> b d H W')\n",
    "            high_res_masks = rearrange(masks[i + 1], 'b H W d -> b d H W')\n",
    "\n",
    "            if high_res_masks.shape[-1] > original_masks.shape[-1]:\n",
    "                high_res_into_low_res_masks = F.interpolate(high_res_masks, (low_res_masks.shape[-2], low_res_masks.shape[-1]), mode='bilinear')\n",
    "                mask_consistency_loss += F.mse_loss(low_res_masks, high_res_into_low_res_masks)\n",
    "\n",
    "        generator_loss = generator_dual_loss + mask_consistency_loss * 1.0\n",
    "    torch.cuda.synchronize()\n",
    "    time_3 = time.time()\n",
    "\n",
    "    with record_function(\"model_backward\"):\n",
    "        generator_loss.mean().backward()\n",
    "    torch.cuda.synchronize()\n",
    "    time_4 = time.time()\n",
    "\n",
    "    forward_t.append(time_2 - time_1)\n",
    "    loss_t.append(time_3 - time_2)\n",
    "    backward_t.append(time_4 - time_3)\n",
    "    \n",
    "print(f\"model_forward : \\t {np.mean(forward_t)} +- {np.std(forward_t)}\")\n",
    "print(f\"loss_calc     : \\t {np.mean(loss_t)} +- {np.std(loss_t)}\")\n",
    "print(f\"model_backward: \\t {np.mean(backward_t)} +- {np.std(backward_t)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a89e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553fe3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc7168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016898b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a33464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
